\chapter{Platform provenance: stato dell'arte}
\label{cha:ppa}
In questo capitolo viene presentata una descrizione dei metodi che rappresentano lo stato dell'arte della \textit{platform provenance analysis} (PPA), prendendo in considerazione i principali lavori proposti in letteratura. Si partirà dall'esaminare una serie di dataset creati dalla comunità scientifica (\ref{sec:dataset}), mettendo in evidenza le caratteristiche e differenze. A seguire verranno presentate le tecniche adottate per l'estrazione di \textit{feature} (\ref{sec:feature}), specificandone l'origine e le possibilità di utilizzo. Saranno poi elencati gli algoritmi di classificazione (\ref{sec:ml_model}), sia quelli già noti che quelli sviluppati ad hoc, e successivamente raggruppati in diverse categorie in base al loro funzionamento. Infine, come conclusione al capitolo, discuteremo i problemi aperti e i possibili sviluppi futuri di questo campo (\ref{sec:cosa_rimane_da_fare}).

\section{Dataset}
\label{sec:dataset}
La realizzazione di un dataset è particolarmente delicata e significativa poiché consente di raccogliere i dati necessari per studiare ed approcciare il problema. Nell'ambito della PPA, si tratta tipicamente di raccolte di immagini e/o video, condivisi tramite uno o più dispositivi e su uno o più social network. Ogni database presenta poi caratteristiche differenti in base al tipo di uso per cui sono stati pensati. Nel caso delle immagini vengono utilizzati differenti formati (es., JPEG, RAW), risoluzioni, livelli di compressione, oltre che un'ampia varietà di soggetti e scene raffigurate. Per quanto riguarda i video, invece, sono stati creati un numero inferiore di dataset a causa delle problematiche legate alla gestione di una mole di dati molto più grande.\\
Il processo di composizione di un dataset può essere riassunto in cinque punti fondamentali: selezione delle immagini di partenza; selezione dei dispositivi (es., smartphone, tablet, computer) da cui condividere le immagini; scelta delle piattaforme social su cui caricare i contenuti; download delle immagini condivise; organizzazione dei dati ottenuti. Di seguito vengono illustrati i principali dataset che possono essere impiegati per la PPA, con le relative caratteristiche.

\begin{itemize}
    \item \textit{VISION} \cite{shullani2017vision}: creato per \textit{l'image source identification} (ISI) e per la \textit{video source identification} (VSI), comprende oltre 34000 immagini e 1900 video provenienti da 35 modelli di smartphone e tablet di 11 diversi brand (es., Apple, Lenovo, Microsoft, Samsung, Sony, etc.). Le immagini sono state condivise in alta e bassa qualità su Facebook e WhatsApp; i video sono stati caricati con la massima risoluzione possibile su WhatsApp e YouTube. I sistemi operativi presi in considerazione sono iOS (dalla versione 7 alla 10), Android (dalla versione 6 alla 7) e Windows Phone OS 8.1.
    
    \item \textit{V-SMUD} \cite{phan2019tracking}: acronimo di \textit{VISION Social Multiple Up-Download}, è formato da 510 immagini JPEG provenienti dal dataset VISION e condivise fino a 3 volte utilizzando tre piattaforme differenti: Facebook, Flickr e Twitter. Le $510\times39 = 19890$ immagini ottenute vanno a comporre il dataset finale.
    
    \item \textit{RAISE} \cite{dang2015raise}: realizzato per l'\textit{image forensics}, questo dataset comprende 8156 immagini in formato originale RAW catturate tramite l'utilizzo di tre diverse macchine fotografiche (Nikon D40, Nikon D90 e Nikon D7000). Le immagini sono state salvate a tre diverse risoluzioni: $3008\times2000$, $4288\times2848$ e $4928\times3264$ pixel. Ognuna di esse è stata poi classificata in una o più delle seguenti categorie: \textit{“outdoor"}, \textit{“indoor"}, \textit{“landscape"}, \textit{“nature"}, \textit{“people"}, \textit{“objects"} e \textit{“buildings"}. RAISE è stato creato con due scopi principali: mettere a disposizione della comunità scientifica un ampio database di immagini per uso forense ed eliminare il problema della privacy legato all'utilizzo di contenuti scaricati dal web. Per facilitare l'utilizzo di RAISE, gli autori hanno anche reso pubblici sottoinsiemi di questo dataset contenenti un numero di elementi pari a 1000 (RAISE-1K), 2000 (RAISE-2K), 4000 (RAISE-4K) e 6000 (RAISE-6K).
    
    \item \textit{R-SMUD} \cite{phan2019tracking}: come V-SMUD, R-SMUD è stato creato a partire da immagini che fanno parte di un altro dataset, in questo caso RAISE. È costituito da 900 immagini con tre risoluzioni differenti ($337\times600$, $1012\times1800$, $1687\times3000$), con un aspect-ratio di $9:16$ e compresse nel formato JPEG in 6 \textit{quality factor} diversi ($QF = 50, 60, 70, 80, 90, 100$). Ogni elemento di R-SMUD è stato in seguito condiviso attraverso tre social network (Facebook, Flickr e Twitter) ottenendo in questo modo 35100 immagini.
    
    \item \textit{SDRG} \cite{rouhi2021no}: dataset costruito con gli obiettivi di identificare il dispositivo che ha effettuato la condivisione (\textit{smartphone identification}) e associare tramite le informazioni a disposizione il corrispondente profilo utente (\textit{user profile linking}). SDRG comprende 4500 immagini, con diverse risoluzioni ottenute da smartphone di 18 brand (es., Apple, LG, Motorola, Nokia, etc.) e successivamente caricate su 4 social network: Facebook, Google Currents, Telegram e WhatsApp.
    
    \item \textit{ISIMA} \cite{Phan2018}: raccoglie immagini condivise su applicazioni di messaggistica istantanea, prendendo in considerazione Facebook Messenger, Telegram e WhatsApp. Queste immagini (in formato JPEG) sono state caricate utilizzando due tipologie di smartphone, ovvero Android e Apple. Le immagini contenute in questo dataset possono essere raggruppate in due categorie: \textit{single-shared}, ovvero condivise una sola volta e \textit{double-shared}, condivise una seconda volta, per un totale di 8400 elementi.
    
    \item \textit{FODB} \cite{hadwiger2021forchheim}: rappresenta il dataset più recente tra quelli menzionati e si pone l'obiettivo di separare il contenuto di un'immagine dalle relative tracce forensi, e mettere a disposizione uno strumento per analizzare le operazioni di compressione effettuate dai social network. La sua realizzazione è avvenuta attraverso l'utilizzo di 25 diversi modelli di smartphone, appartenenti a 9 brand. I social media adottati per la condivisione sono: Facebook, Instagram, Telegram, Twitter e WhatsApp.
    
\end{itemize}
La tabella \ref{tab:lista_dataset} riporta una sintesi delle principali caratteristiche dei dataset presentati. 

\begin{center}
    \begin{adjustbox}{max width=\textwidth}
    \begin{tabular}{ccccccc}
        \hline
        \\[-1em]
        \textbf{Dataset} & \textbf{Immagini} & \textbf{Video} & \textbf{N. immagini} & \textbf{N. video} & \textbf{Brand} & \textbf{Social network}\\[-1em]\\
        \hline
        \\
        VISION & \ding{51} & \ding{51} & 34427 & 1914 & \parbox{5cm}{Apple, Asus, Huawei, Lenovo, LG, Microsoft, OnePlus, Samsung, Sony, Wiko, Xiaomi} & \parbox{5cm}{Facebook, WhatsApp, YouTube}\\\\
        \\
        V-SMUD & \ding{51} & \ding{55} & 19890 & - & \parbox{5cm}{Apple, Asus, Huawei, Lenovo, LG, Microsoft, OnePlus, Samsung, Sony, Wiko, Xiaomi} & \parbox{5cm}{Facebook, Flickr, Twitter}\\\\
        \\
        RAISE & \ding{51} & \ding{55} & 8156 & - & \parbox{5cm}{Nikon} & \parbox{5cm}{ \begin{center} - \end{center} }\\\\
        \\
        R-SMUD & \ding{51} & \ding{55} & 35100 & - & \parbox{5cm}{ \begin{center} - \end{center}} & \parbox{5cm}{Facebook, Flickr, Twitter}\\\\
        \\
        SDRG & \ding{51} & \ding{55} & 4500 & - & \parbox{5cm}{Apple, HTC, Huawei, LG, Motorola, Nokia, Samsung, Sony} & \parbox{5cm}{Facebook, Google Currents, Telegram, WhatsApp}\\\\
        \\
        ISIMA & \ding{51} & \ding{55} & 9100 & - & \parbox{5cm}{Apple, Asus, Huawei, Lenovo, LG, Microsoft, OnePlus, Samsung, Sony, Wiko, Xiaomi} & \parbox{5cm}{Facebook Messenger, Telegram, WhatsApp}\\\\
        \\
        FODB & \ding{51} & \ding{55} & 23106 & - & \parbox{5cm}{Apple, BQ, Google, Huawei, LG, Motorola, Samsung, Sony, Wiko} & \parbox{5cm}{Facebook, Instagram, Telegram, Twitter, WhatsApp}\\\\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
\end{center}
\captionof{table}{\label{tab:lista_dataset}Da sinistra a destra sono riportati: il nome, la presenza di immagini e/o video tramite i simboli \ding{51} e \ding{55}; il numero di immagini/video presenti; i brand dei dispositivi considerati; le piattaforme social utilizzate~\cite{pasquini2021media}.}

\section{Estrazione feature}
\label{sec:feature}
Partendo dai dati raccolti nella fase precedente, si passa alla fase di estrazione di \textit{feature}. Queste sono ricavate in modo tale da analizzare le operazioni subite dai media digitali durante la condivisione e le fasi di upload/download. Infatti, i processi a cui vengono sottoposti i contenuti multimediali contribuiscono a modificarli lasciando tracce distintive. Queste modifiche, nella maggior parte dei casi, sono univoche e rappresentano indizi importanti per ricostruire la storia di un contenuto digitale.\\
Come menzionato nel capitolo introduttivo, le \textit{feature} possono essere ricavate in due modi: a partire dall'analisi del segnale oppure attraverso i metadati. Nel primo caso viene analizzato il cambiamento avvenuto nei pixel dell'immagine dopo la condivisione; nel secondo, si cercano eventuali modifiche apportate dalle piattaforme sulle strutture dati degli oggetti digitali. Queste \textit{feature} vengono infine raggruppate sotto forma di vettori numerici. Gli studi condotti nel campo della PPA hanno anche sviluppato tecniche che fondono assieme segnale e metadati, per creare metodi ibridi.\\
Verranno ora presentate alcune tecniche che utilizzano \textit{feature} basate sull'analisi del segnale. In letteratura scientifica sono stati proposti nel tempo molteplici approcci. Per esempio, in~\cite{moltisanti2015image} vengono esaminate le modifiche apportate sulle immagini dall'algoritmo utilizzato da Facebook al fine di identificarne le operazioni svolte. Gli aspetti su cui è stata posta particolare attenzione sono due: come le immagini vengono ridimensionate a seguito del caricamento e in che modo queste sono compresse. Dai risultati ottenuti è emerso che un'immagine pubblicata tramite Facebook viene ridimensionata solo in alcune circostanze, in particolare sulla base del numero di pixel nel lato più lungo dell'immagine e dell'attivazione o meno dell'opzione di caricamento in alta qualità.\\
Sempre nell'ambito dell'analisi del segnale un aiuto significativo è rappresentato da \textit{feature} di tipo statistico, come per esempio gli istogrammi dei coefficienti DCT (\textit{Discrete Cosine Transform}). La costruzione di tali elementi avviene suddividendo l'immagine di partenza in un determinato numero di blocchi, di dimensione fissata, per ognuno dei quali si calcolano i relativi coefficienti DCT. Infine, gli istogrammi dei coefficienti vanno a costituire il vettore di \textit{feature}. Molteplici studi seguono questa strada~\cite{caldelli2017image, amerini2017tracing, amerini2019social} perché le tracce lasciate nelle immagini non possono essere eliminate, a differenza dei metadati facilmente rimovibili. In~\cite{amerini2019social}, oltre a considerare \textit{feature} basate sui coefficienti DCT, ne vengono estratte anche di relative al rumore introdotto nelle immagini dai social network.\\
Esistono poi una serie di lavori che utilizzano i metadati come principale fonte di informazioni. Un esempio è dato da~\cite{mullan2019forensic} che, attraverso un'analisi dei metadati, ha permesso di risalire ai dispositivi (smartphone Apple) utilizzati per la condivisione delle immagini. Obiettivo principale di questo studio era dimostrare che i soli metadati sono sufficienti a identificare con elevata precisione le diverse versioni software impiegate da questi dispositivi. Sono stati utilizzati i dati EXIF (\textit{Exchangeable Image File Format}, uno standard che codifica specifiche informazioni associate ad un'immagine, quali i valori di scatto, la data e l'ora di acquisizione \cite{nasim}) e i parametri dell'algoritmo di codifica JPEG. In~\cite{mullan2019forensic}, è stato mostrato come sia possibile suddividere tali informazioni in due categorie: \textit{“camera data"} e \textit{“other data"}. Nonostante i metadati rappresentino un'importante fonte di informazioni, in alcuni casi vengono rimossi dai social media nel momento in cui si effettua l'upload. Di conseguenza il loro utilizzo non rappresenta sempre una via percorribile.\\
Infine, sono stati sviluppati una serie di metodi che sfruttano in combinazione \textit{feature} derivate dal segnale e dai metadati. Se da un lato per questi approcci si riscontrano difficoltà nel modo di unire i due tipi di \textit{feature}, la loro fusione permette di sfruttare i punti di forza di entrambe. A tal proposito,~\cite{phan2018identifying} adotta un approccio basato sulla fusione di \textit{feature} per applicazioni di messaggistica istantanea, mentre \cite{verde2021multi} si concentra sui social network. Le \textit{feature} utilizzate nel primo caso sono il risultato della composizione di istogrammi DCT (369) e metadati (152) estratte dalle immagini, per un totale di 521 elementi. In~\cite{verde2021multi} ne viene presentato anche un terzo insieme chiamato HEADER che contiene informazioni ricavate dall'header JPEG delle immagini.

\section{Modelli di machine learning}
\label{sec:ml_model}
Il passo successivo della PPA è rappresentato dalla classificazione automatica, tramite la quale i dati a disposizione vengono suddivisi in cluster, ad ognuno dei quali è associata un'etichetta, o \textit{label}. Per effettuare questa operazione vengono tipicamente utilizzati algoritmi di \textit{machine learning}, che apprendono automaticamente il criterio ottimo di separazione delle \textit{feature} estratte. Ad oggi possiamo suddividere i lavori proposti in due principali categorie: quelli che adottato classici metodi di classificazione supervisionata e quelli che utilizzano metodi basati sul \textit{deep learning}. Nel primo caso, gli algoritmi più utilizzati sono \textit{random forest}~\cite{phan2018identifying, mullan2019forensic, caldelli2017image, verde2021multi}, \textit{decision tree}~\cite{giudice2017classification} e \textit{support vector machine}~\cite{phan2018identifying}. Per quanto riguarda il \textit{deep learning}, i metodi più utilizzati si basano sulle \textit{convolutional neural network} (CNN)~\cite{amerini2019social, amerini2017tracing, phan2019tracking}. Queste ultime stanno assumendo sempre più importanza data la possibilità di apprendere automaticamente le \textit{feature} più rappresentative direttamente dai dati e le elevate performance ottenibili.

\section{Problemi aperti}
\label{sec:cosa_rimane_da_fare}
Nonostante i progressi effettuati nel campo della PPA, vi sono ancora una serie di domande aperte. Innanzitutto, la maggior parte delle tecniche presentate si concentra sulle immagini. Esse costituiscono un dominio di studio più semplice rispetto ai video, per le ragioni già citate. Come riportato in~\cite{pasquini2021media}, tutti i metodi sviluppati sino a questo momento utilizzano approcci induttivi piuttosto che deduttivi a causa dell'assenza di procedimenti standard per eseguire le operazioni. Per esempio, l'affidabilità delle tecniche adottate (in termini di performance) è fortemente dipendente dalla qualità dei dati prodotti, e dunque lo sviluppo di nuovi metodi può risultare difficile nel momento in cui le informazioni a disposizione non sono sufficienti o adeguate. I lavori effettuati nell'ambito della PPA tendono a considerare più social network per ricostruire la catena di condivisioni, non ponendo particolare attenzione al riconoscimento del dispositivo o sistema adottato per il caricamento dei media digitali. Questo ultimo elemento è oggetto di discussione del prossimo capitolo.


